{
  "userId": 134841503,
  "authorName": "Ted Larson Freeman",
  "from": "&quot;Ted Larson Freeman&quot; &lt;freeman@...&gt;",
  "profile": "tedf255",
  "replyTo": "LIST",
  "senderId": "naHuao5lsCqzbPuW2XQxmNmCZyOljGOytzjIXoc-02X4-Wq71TgqZIYDM31N1lqSuGtHFPsw-aMlm3HzuXtllDmFPrHeViV890M-trfpYfdm4O4_wV0C3Q",
  "spamInfo": {
    "isSpam": false,
    "reason": "12"
  },
  "subject": "Re: [Read_Alphabet] QS news update",
  "postDate": "1194973722",
  "msgId": 1439,
  "canDelete": false,
  "contentTrasformed": false,
  "systemMessage": false,
  "headers": {
    "messageIdInHeader": "PDVkODcyOWYwMDcxMTEzMDkwOGwyMWZkYjc4OGgyZGViZDExZWIzNTA1ODZlQG1haWwuZ21haWwuY29tPg==",
    "inReplyToHeader": "PDQ3Mzk1MTdBLjEwNzA0MDdAaWdsb3UuY29tPg==",
    "referencesHeader": "PDQ3Mzk1MTdBLjEwNzA0MDdAaWdsb3UuY29tPg=="
  },
  "prevInTopic": 1438,
  "nextInTopic": 1440,
  "prevInTime": 1438,
  "nextInTime": 1440,
  "topicId": 1434,
  "numMessagesInTopic": 69,
  "msgSnippet": "Hi Paul, I continue to be quite impressed by your news transliteration program. To err on the side of having too many name dots is fine--it doesn t slow me",
  "messageBody": "<div id=\"ygrps-yiv-930029529\">Hi Paul,<br/>\n<br/>\nI continue to be quite impressed by your news transliteration program.<br/>\nTo err on the side of having too many name dots is fine--it doesn&#39;t<br/>\nslow me down at all, whereas having too few did.<br/>\n<br/>\nCould you tell us how you are handling the CMU phonemes? Looking at<br/>\nthe first paragraph of today&#39;s American news, I see that &quot;Robert&quot; is<br/>\nwritten with #32 while &quot;Washington&quot; is written with #33. In the second<br/>\nsentence, &quot;drop&quot; is written with #34. Looking these words up in the<br/>\nCMU dictionary:<br/>\n<br/>\nROBERT  R AA1 B ER0 T<br/>\nWASHINGTON  W AA1 SH IH0 NG T AH0 N<br/>\nDROP  D R AA1 P<br/>\n<br/>\nThey all use &#39;AA&#39;, the &quot;odd&quot; phoneme. This makes me wonder--are you<br/>\nusing a different dictionary now? If not, you must have a more<br/>\nsophisticated algorithm than simple one-to-one substitution.<br/>\n<br/>\nHere are the CMU entries for the relevant lexical sets:<br/>\n<br/>\nLOT  L AA1 T<br/>\nCLOTH  K L AO1 TH<br/>\nTHOUGHT  TH AO1 T<br/>\nPALM  P AA1 M<br/>\n<br/>\nI would have been inclined to use #32 for &#39;AA&#39; and #33 for &#39;AO&#39;.<br/>\n<br/>\n(Reference: the full CMU phoneme set is here:<br/>\n<a rel=\"nofollow\" target=\"_blank\" href=\"http://www.speech.cs.cmu.edu/cgi-bin/cmudict.)\">http://www.speech.cs.cmu.edu/cgi-bin/cmudict.)</a><br/>\n<br/>\nTed<br/>\n<br/>\n<br/>\n<blockquote><span title=\"qreply\"> On Nov 12, 2007 11:25 PM, Paul Tremblay &lt;<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:phthenry@...\">phthenry@...</a>&gt; wrote:<br/>\n&gt;<br/>\n&gt;<br/>\n&gt;<br/>\n&gt;<br/>\n&gt;<br/>\n&gt;<br/>\n&gt; I have worked on making better PDF news documents.<br/>\n&gt;<br/>\n&gt;  1. The web junk (a page of just links, for example) should not appear<br/>\n&gt;  anymore.<br/>\n&gt;<br/>\n&gt;  2. I have fixed the conversion so that it puts in name dots. However,<br/>\n&gt;  the conversion now puts in too many such dots. The problem is that I put<br/>\n&gt;  a name dot for every capitalized word that does not start a sentence.<br/>\n&gt;  (Sometimes the conversion doesn&#39;t recognize the start of a sentence,<br/>\n&gt;  such as after a title.) This means words like &quot;Tuesday&quot; gets<br/>\n&gt;  capitalized. In order to fix this problem, I have to change my 100,000<br/>\n&gt;  word dictionary so that words like &#39;chavez&quot; gets changed to &quot;Chavez,&quot;<br/>\n&gt;  but given the enormous size of the dictionary, I can&#39;t change very many<br/>\n&gt;  names. So we either have to have too many dots, or not enough, at least<br/>\n&gt;  until we get a better dictionary.<br/>\n&gt;<br/>\n&gt;  Paul<br/>\n&gt; </span></blockquote></div>",
  "specialLinks": [],
  "rawEmail": "Return-Path: &lt;tedf255@...&gt;\r\nX-Sender: tedf255@...\r\nX-Apparently-To: Read_Alphabet@yahoogroups.com\r\nX-Received: (qmail 26399 invoked from network); 13 Nov 2007 17:08:47 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m52.grp.scd.yahoo.com with QMQP; 13 Nov 2007 17:08:47 -0000\r\nX-Received: from unknown (HELO nf-out-0910.google.com) (64.233.182.189)\n  by mta18.grp.scd.yahoo.com with SMTP; 13 Nov 2007 17:08:46 -0000\r\nX-Received: by nf-out-0910.google.com with SMTP id b21so1307666nfd\n        for &lt;Read_Alphabet@yahoogroups.com&gt;; Tue, 13 Nov 2007 09:08:42 -0800 (PST)\r\nX-Received: by 10.78.180.18 with SMTP id c18mr6967286huf.1194973722423;\n        Tue, 13 Nov 2007 09:08:42 -0800 (PST)\r\nX-Received: by 10.78.37.11 with HTTP; Tue, 13 Nov 2007 09:08:42 -0800 (PST)\r\nMessage-ID: &lt;5d8729f00711130908l21fdb788h2debd11eb350586e@...&gt;\r\nDate: Tue, 13 Nov 2007 09:08:42 -0800\r\nTo: Read_Alphabet@yahoogroups.com\r\nIn-Reply-To: &lt;4739517A.1070407@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: 7bit\r\nContent-Disposition: inline\r\nReferences: &lt;4739517A.1070407@...&gt;\r\nX-Google-Sender-Auth: 48a8db71b98debac\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ted Larson Freeman&quot; &lt;freeman@...&gt;\r\nSubject: Re: [Read_Alphabet] QS news update\r\nX-Yahoo-Group-Post: member; u=134841503; y=LE4L3X3M2cULwb6M5nGo8iXLOCUrZXwRBgc5MY2PUAZCpw\r\nX-Yahoo-Profile: tedf255\r\n\r\nHi Paul,\n\nI continue to be quite impressed by your news transliteration program.\nTo err on the side of having too many name dots is fine--it doesn&#39;t\nslow me down at all, whereas having too few did.\n\nCould you tell us how you are handling the CMU phonemes? Looking at\nthe first paragraph of today&#39;s American news, I see that &quot;Robert&quot; is\nwritten with #32 while &quot;Washington&quot; is written with #33. In the second\nsentence, &quot;drop&quot; is written with #34. Looking these words up in the\nCMU dictionary:\n\nROBERT  R AA1 B ER0 T\nWASHINGTON  W AA1 SH IH0 NG T AH0 N\nDROP  D R AA1 P\n\nThey all use &#39;AA&#39;, the &quot;odd&quot; phoneme. This makes me wonder--are you\nusing a different dictionary now? If not, you must have a more\nsophisticated algorithm than simple one-to-one substitution.\n\nHere are the CMU entries for the relevant lexical sets:\n\nLOT  L AA1 T\nCLOTH  K L AO1 TH\nTHOUGHT  TH AO1 T\nPALM  P AA1 M\n\nI would have been inclined to use #32 for &#39;AA&#39; and #33 for &#39;AO&#39;.\n\n(Reference: the full CMU phoneme set is here:\nhttp://www.speech.cs.cmu.edu/cgi-bin/cmudict.)\n\nTed\n\n\nOn Nov 12, 2007 11:25 PM, Paul Tremblay &lt;phthenry@...&gt; wrote:\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; I have worked on making better PDF news documents.\n&gt;\n&gt;  1. The web junk (a page of just links, for example) should not appear\n&gt;  anymore.\n&gt;\n&gt;  2. I have fixed the conversion so that it puts in name dots. However,\n&gt;  the conversion now puts in too many such dots. The problem is that I put\n&gt;  a name dot for every capitalized word that does not start a sentence.\n&gt;  (Sometimes the conversion doesn&#39;t recognize the start of a sentence,\n&gt;  such as after a title.) This means words like &quot;Tuesday&quot; gets\n&gt;  capitalized. In order to fix this problem, I have to change my 100,000\n&gt;  word dictionary so that words like &#39;chavez&quot; gets changed to &quot;Chavez,&quot;\n&gt;  but given the enormous size of the dictionary, I can&#39;t change very many\n&gt;  names. So we either have to have too many dots, or not enough, at least\n&gt;  until we get a better dictionary.\n&gt;\n&gt;  Paul\n&gt;  \n\n"
}
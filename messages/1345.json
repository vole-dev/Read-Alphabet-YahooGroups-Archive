{
  "userId": 326670551,
  "authorName": "Anthony Grahn",
  "from": "&quot;Anthony Grahn&quot; &lt;othermale@...&gt;",
  "profile": "othermale",
  "replyTo": "LIST",
  "senderId": "KjGfcJyAQT4Kfn6bjcc3p2vBWx9saDkHA-q2ClCflh0j52SVBpMxaTY2_p9DXRndLyOwgy94iUmtg8j6-KnHbuermuM__DstUl5OaA",
  "spamInfo": {
    "isSpam": false,
    "reason": "6"
  },
  "subject": "Re: Lexical sets and QS letters",
  "postDate": "1194357156",
  "msgId": 1345,
  "canDelete": false,
  "contentTrasformed": false,
  "systemMessage": false,
  "headers": {
    "messageIdInHeader": "PGZncHJqNCs3ZTlxQGVHcm91cHMuY29tPg==",
    "inReplyToHeader": "PDQ3MkZBRkQyLjYwNTAzMDRAaWdsb3UuY29tPg=="
  },
  "prevInTopic": 1343,
  "nextInTopic": 1348,
  "prevInTime": 1344,
  "nextInTime": 1346,
  "topicId": 1286,
  "numMessagesInTopic": 73,
  "msgSnippet": "I ve grayed out several more lexical groups (so to speak)  to allow CLOTH, THOUGHT, LOT, PALM permutations and NEAR, KIT, FLEECE. I m concerned that #32, #33,",
  "messageBody": "<div id=\"ygrps-yiv-231080583\">I&#39;ve grayed out several more lexical groups (so to speak)  to allow<br/>\nCLOTH, THOUGHT, LOT, PALM permutations and NEAR, KIT, FLEECE. I&#39;m<br/>\nconcerned that #32, #33, #39 have no &quot;black&quot; lexical groups and how<br/>\nanyone but the chart&#39;s author could ever figure out what the letters<br/>\n#32, #33, #39 should be used for.<br/>\n<br/>\n<a rel=\"nofollow\" target=\"_blank\" href=\"http://groups.yahoo.com/group/Read_Alphabet/files/Pronunciation/fig1.jpg\">http://groups.yahoo.com/group/Read_Alphabet/files/Pronunciation/fig1.jpg</a><br/>\n<br/>\nAlas, going down this path is starting to cause some oddities.<br/>\n<br/>\n- The CURE merge with THOUGHT/NORTH/FORCE would have to be done under<br/>\n#33. But could anyone in America read Key+Ye+Awe+Roe as the word &quot;cure&quot;<br/>\n<br/>\n- Allowing the TRAP-LOT merger looks like it will make #30 unintelligible.<br/>\n<br/>\n<br/>\n Anyone have an idea about these?<br/>\n<br/>\n<br/>\n<br/>\n<blockquote><span title=\"ireply\"> &gt; &gt; Issue 3:<br/>\n&gt; &gt;   Complexity: Lexical set use is going to be harder to explain than a<br/>\n&gt; &gt; static IPA map. <br/>\n&gt; <br/>\n&gt; Not really.  You list a number of words that are firmly (that is,<br/>\n&gt; cross-dialectally) in each lexical set as examples.  Reed&#39;s problem is<br/>\n&gt; that he only lists two words and they aren&#39;t all well-chosen.<br/>\n&gt; <br/>\n<br/>\n </span></blockquote>If we can use lexical groups to pre build a list of sample words for<br/>\neach QS letter for every accent and post that prominently then we<br/>\nwould be in absolutely great shape.<br/>\n- we would not need any IPA charts<br/>\n- we would not have to worry about massively complex explanations<br/>\nabout moving gray words around. Only the authors of the pre built<br/>\ncharts would have to know them.<br/>\n<br/>\nIf lexical sets end up producing these pre built charts I am certainly<br/>\nfor it.<br/>\n<br/>\nOf particular interest would be the Australian chart re: legibility.<br/>\n<br/>\n<br/>\n<blockquote><span title=\"ireply\"> &gt; &gt; Issue 2:<br/>\n&gt; &gt; There can not be some many &quot;re-assignable&quot; lexical sets that a given<br/>\n&gt; &gt; accent can arrange the chart in more than one way. If this were<br/>\n&gt; &gt; possible, people with the same accent would use different letters in<br/>\n&gt; &gt; spelling the same word. Each *person* maybe consistent but within the<br/>\n&gt; &gt; accent there would be wide variation.<br/>\n&gt; <br/>\n&gt; I too agree with John&#39;s point. I also am more for standardized<br/>\n </span></blockquote>spelling, <br/>\n<blockquote><span title=\"ireply\"> &gt; but I don&#39;t think it need be so rigid as TO.<br/>\n<br/>\n </span></blockquote>Issue 2 becomes moot if we pre-build all the sample words for each<br/>\naccent. If not then here is the scenario:<br/>\nSuppose there are two ways for an Australian to arrange the lexical<br/>\nsets for his accent and one of them is not official. Two people in the<br/>\nsame house with the same accent may build different<br/>\nletter-lexical-set-maps. One may be able to write clearly to Americans<br/>\nas promised but they may not be able to write clearly to each other!<br/>\nPersonally I have no love for standardized spelling but even I have my<br/>\nlimits.<br/>\n<br/>\n<br/>\n<blockquote><span title=\"ireply\"> &gt; Your method gives much better examples, and handles the <br/>\n&gt; problems created by merges and different dialects. A new QS user need <br/>\n&gt; only print out the right chart and use it as a guide, exactly as users <br/>\n&gt; have been using the QS manual. In addition, though, there would be <br/>\n&gt; useful information on what to do with difficult situations, and<br/>\n </span></blockquote>ideally, <br/>\n<blockquote><span title=\"ireply\"> &gt; this information would be grouped under dialects. For example, we could <br/>\n&gt; have an area titled &quot;North American Speaker,&quot; which would say something <br/>\n&gt; like &quot;You may not perceive a difference between On, Ah, and Awe.<br/>\n </span></blockquote>Here is <br/>\n<blockquote><span title=\"ireply\"> &gt; how you would write those letters...&quot;<br/>\n<br/>\n </span></blockquote>Also explaining/justifying Roar to non-rhotic accents is a good one<br/>\n(once we figure out consistent rules ourselves ;-)</div>",
  "specialLinks": [],
  "rawEmail": "Return-Path: &lt;othermale@...&gt;\r\nX-Sender: othermale@...\r\nX-Apparently-To: Read_Alphabet@yahoogroups.com\r\nX-Received: (qmail 27841 invoked from network); 6 Nov 2007 13:52:39 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m44.grp.scd.yahoo.com with QMQP; 6 Nov 2007 13:52:39 -0000\r\nX-Received: from unknown (HELO n36d.bullet.mail.sp1.yahoo.com) (66.163.168.190)\n  by mta16.grp.scd.yahoo.com with SMTP; 6 Nov 2007 13:52:38 -0000\r\nX-Received: from [216.252.122.218] by n36.bullet.mail.sp1.yahoo.com with NNFMP; 06 Nov 2007 13:52:38 -0000\r\nX-Received: from [66.218.69.2] by t3.bullet.sp1.yahoo.com with NNFMP; 06 Nov 2007 13:52:38 -0000\r\nX-Received: from [66.218.66.84] by t2.bullet.scd.yahoo.com with NNFMP; 06 Nov 2007 13:52:37 -0000\r\nDate: Tue, 06 Nov 2007 13:52:36 -0000\r\nTo: Read_Alphabet@yahoogroups.com\r\nMessage-ID: &lt;fgprj4+7e9q@...&gt;\r\nIn-Reply-To: &lt;472FAFD2.6050304@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Anthony Grahn&quot; &lt;othermale@...&gt;\r\nSubject: Re: Lexical sets and QS letters\r\nX-Yahoo-Group-Post: member; u=326670551; y=W7ZUoywP8WiH66bwc52iartxilA2f_uS9oEzsHHvXu3djRYS\r\nX-Yahoo-Profile: othermale\r\n\r\n  I&#39;ve grayed out several more lexical groups (so to speak)  to allow\nCLOTH=\r\n, THOUGHT, LOT, PALM permutations and NEAR, KIT, FLEECE. I&#39;m\nconcerned that=\r\n #32, #33, #39 have no &quot;black&quot; lexical groups and how\nanyone but the chart&#39;=\r\ns author could ever figure out what the letters\n#32, #33, #39 should be use=\r\nd for.\n\nhttp://groups.yahoo.com/group/Read_Alphabet/files/Pronunciation/fig=\r\n1.jpg\n\nAlas, going down this path is starting to cause some oddities.\n\n- Th=\r\ne CURE merge with THOUGHT/NORTH/FORCE would have to be done under\n#33. But =\r\ncould anyone in America read Key+Ye+Awe+Roe as the word &quot;cure&quot;\n\n- Allowing =\r\nthe TRAP-LOT merger looks like it will make #30 unintelligible.\n\n\n Anyone h=\r\nave an idea about these?\n\n\n\n&gt; &gt; Issue 3:\n&gt; &gt;   Complexity: Lexical set use =\r\nis going to be harder to explain than a\n&gt; &gt; static IPA map. \n&gt; \n&gt; Not reall=\r\ny.  You list a number of words that are firmly (that is,\n&gt; cross-dialectall=\r\ny) in each lexical set as examples.  Reed&#39;s problem is\n&gt; that he only lists=\r\n two words and they aren&#39;t all well-chosen.\n&gt; \n\nIf we can use lexical group=\r\ns to pre build a list of sample words for\neach QS letter for every accent a=\r\nnd post that prominently then we\nwould be in absolutely great shape.\n- we w=\r\nould not need any IPA charts\n- we would not have to worry about massively c=\r\nomplex explanations\nabout moving gray words around. Only the authors of the=\r\n pre built\ncharts would have to know them.\n\nIf lexical sets end up producin=\r\ng these pre built charts I am certainly\nfor it.\n\nOf particular interest wou=\r\nld be the Australian chart re: legibility.\n\n\n&gt; &gt; Issue 2:\n&gt; &gt; There can not=\r\n be some many &quot;re-assignable&quot; lexical sets that a given\n&gt; &gt; accent can arra=\r\nnge the chart in more than one way. If this were\n&gt; &gt; possible, people with =\r\nthe same accent would use different letters in\n&gt; &gt; spelling the same word. =\r\nEach *person* maybe consistent but within the\n&gt; &gt; accent there would be wid=\r\ne variation.\n&gt; \n&gt; I too agree with John&#39;s point. I also am more for standar=\r\ndized\nspelling, \n&gt; but I don&#39;t think it need be so rigid as TO.\n\nIssue 2 be=\r\ncomes moot if we pre-build all the sample words for each\naccent. If not the=\r\nn here is the scenario:\nSuppose there are two ways for an Australian to arr=\r\nange the lexical\nsets for his accent and one of them is not official. Two p=\r\neople in the\nsame house with the same accent may build different\nletter-lex=\r\nical-set-maps. One may be able to write clearly to Americans\nas promised bu=\r\nt they may not be able to write clearly to each other!\nPersonally I have no=\r\n love for standardized spelling but even I have my\nlimits.\n\n\n&gt; Your method =\r\ngives much better examples, and handles the \n&gt; problems created by merges a=\r\nnd different dialects. A new QS user need \n&gt; only print out the right chart=\r\n and use it as a guide, exactly as users \n&gt; have been using the QS manual. =\r\nIn addition, though, there would be \n&gt; useful information on what to do wit=\r\nh difficult situations, and\nideally, \n&gt; this information would be grouped u=\r\nnder dialects. For example, we could \n&gt; have an area titled &quot;North American=\r\n Speaker,&quot; which would say something \n&gt; like &quot;You may not perceive a differ=\r\nence between On, Ah, and Awe.\nHere is \n&gt; how you would write those letters.=\r\n..&quot;\n\nAlso explaining/justifying Roar to non-rhotic accents is a good one\n(o=\r\nnce we figure out consistent rules ourselves ;-)  \n\n\n\n"
}